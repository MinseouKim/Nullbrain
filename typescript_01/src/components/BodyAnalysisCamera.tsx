import React, { useEffect, useRef, useState } from "react";
import { KP, Size } from "../poseLib/poseTypes";
import type { SegMask } from "../poseLib/segmentation";

type Props = {
  running: boolean;
  onPose?: (arg: { kp: KP; size: Size }) => void;
  focusRoi?: { x1: number; y1: number; x2: number; y2: number } | null;
  mirrored?: boolean; // if true, mirror visually only on canvas
  getSegmentation?: (source: HTMLCanvasElement | HTMLVideoElement) => Promise<SegMask | null>;
  onSegMask?: (mask: SegMask) => void;
};

const CDN = {
  cam: "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1640029074/camera_utils.js",
  draw: "https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1620248257/drawing_utils.js",
  pose: "https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/pose.js",
};

// script loader
const loadScript = (src: string) =>
  new Promise<void>((resolve, reject) => {
    if (document.querySelector(`script[src="${src}"]`)) return resolve();
    const s = document.createElement("script");
    s.src = src;
    s.crossOrigin = "anonymous";
    s.onload = () => resolve();
    s.onerror = () => reject(new Error(`Script load error: ${src}`));
    document.head.appendChild(s);
  });

let scriptsReady: Promise<void> | null = null;
function ensureScripts() {
  if (!scriptsReady) {
    scriptsReady = Promise.all([loadScript(CDN.cam), loadScript(CDN.draw), loadScript(CDN.pose)]).then(() => {});
  }
  return scriptsReady;
}

const BodyAnalysisCamera: React.FC<Props> = ({
  running,
  onPose,
  focusRoi,
  mirrored = true,
  getSegmentation,
  onSegMask,
}) => {
  const [feedback, setFeedback] = useState("AI ëª¨ë¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...");
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const cameraRef = useRef<any>(null);
  const poseRef = useRef<any>(null);

  const frameCount = useRef(0);

  // seg throttle/lock
  const segPending = useRef(false);
  const lastSegTs = useRef(0);

  // ğŸ”§ ìµœì‹  ì½œë°±/í”„ë¡œí¼í‹°ë¥¼ ì°¸ì¡°í•˜ê¸° ìœ„í•œ refs (í´ë¡œì € ê³ ì°© ë°©ì§€)
  const onPoseRef = useRef<Props["onPose"] | null>(null);
const focusRoiRef = useRef<Props["focusRoi"] | null>(null);
const getSegRef = useRef<Props["getSegmentation"] | null>(null);
const onSegMaskRef = useRef<Props["onSegMask"] | null>(null);

  const runningRef = useRef<boolean>(running);


  useEffect(() => { onPoseRef.current = onPose ?? null; }, [onPose]);
useEffect(() => { focusRoiRef.current = focusRoi ?? null; }, [focusRoi]);
useEffect(() => { getSegRef.current = getSegmentation ?? null; }, [getSegmentation]);
useEffect(() => { onSegMaskRef.current = onSegMask ?? null; }, [onSegMask]);

useEffect(() => {
  runningRef.current = running;
  setFeedback(running ? "ì²´í˜• ë¶„ì„ ì¤‘... ìì„¸ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”." : "ë¶„ì„ì´ ì¼ì‹œì •ì§€ ë˜ì—ˆìŠµë‹ˆë‹¤.");
}, [running]);

  // âš ï¸ ì´ˆê¸°í™” ì´í™íŠ¸: runningì— ì˜ì¡´í•˜ì§€ ì•Šë„ë¡ ìˆ˜ì • (running í† ê¸€ ì‹œ ì¬ì´ˆê¸°í™” ë°©ì§€)
  useEffect(() => {
    let cancelled = false;

    async function init() {
      try {
        await ensureScripts();
      } catch (err) {
        console.error("MediaPipe script load failed:", err);
        setFeedback("AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
        return;
      }
      if (cancelled) return;

      const Pose = (window as any).Pose;
      const Camera = (window as any).Camera;
      const drawConnectors = (window as any).drawConnectors;
      const drawLandmarks = (window as any).drawLandmarks;
      const POSE_CONNECTIONS = (window as any).POSE_CONNECTIONS;

      if (!Pose || !Camera || !videoRef.current || !canvasRef.current) return;

      const pose = new Pose({
        locateFile: (f: string) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/${f}`,
      });
      pose.setOptions({
        modelComplexity: 2,          // more stable (heavier)
        smoothLandmarks: true,
        minDetectionConfidence: 0.6,
        minTrackingConfidence: 0.6,
        selfieMode: false,           // keep semantic left/right; we mirror only in canvas
      });
      poseRef.current = pose;

      pose.onResults(async (results: any) => {
        if (!canvasRef.current) return;
        if (!results?.image) return;
        const canvas = canvasRef.current!;
        const ctx = canvas.getContext("2d")!;
        canvas.width = results.image.width;
        canvas.height = results.image.height;

        const withMirror = (fn: () => void) => {
          if (!mirrored) { fn(); return; }
          ctx.save();
          ctx.translate(canvas.width, 0);
          ctx.scale(-1, 1);
          fn();
          ctx.restore();
        };

        // draw frame
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        withMirror(() => {
          ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
        });

        // pose callback (landmarks are original-space)
        const kp: KP = results.poseLandmarks ? results.poseLandmarks : [];
onPoseRef.current?.({ kp, size: { w: canvas.width, h: canvas.height } });

        // skeleton overlay
        if (results.poseLandmarks) {
          withMirror(() => {
            drawConnectors(ctx, results.poseLandmarks, POSE_CONNECTIONS, { lineWidth: 3 });
            drawLandmarks(ctx, results.poseLandmarks, { lineWidth: 1 });
          });
        }

        // ROI overlay (ìµœì‹  ê°’ ref ì‚¬ìš©)
        const roi = focusRoiRef.current;
        if (roi) {
          const { x1, y1, x2, y2 } = roi;
          withMirror(() => {
            ctx.setLineDash([6, 4]);
            ctx.lineWidth = 2;
            ctx.strokeStyle = "#39b3ff";
            ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
          });
        }

        // segmentation throttled: 5 frames + 200ms (ìµœì‹  í•¨ìˆ˜ ref ì‚¬ìš©)
        frameCount.current++;
const now = performance.now();
const wantSeg = !!(getSegRef.current && onSegMaskRef.current && frameCount.current % 5 === 0);
if (wantSeg && !segPending.current && now - lastSegTs.current > 200) {
  segPending.current = true;
  try {
    // í˜„ì¬ ref ìŠ¤ëƒ…ìƒ·ì„ ë¡œì»¬ ë³€ìˆ˜ë¡œ ì¡ì•„ ì•ˆì „í•˜ê²Œ ì‚¬ìš©
    const segFn = getSegRef.current!;
    const segCb = onSegMaskRef.current!;
const src = videoRef.current ?? canvasRef.current;
if (src) {
   const mask = await segFn(src);
   if (mask) segCb(mask);
 }
  } catch {
  } finally {
    lastSegTs.current = performance.now();
    segPending.current = false;
  }
}
      });

      cameraRef.current = new (window as any).Camera(videoRef.current, {
  onFrame: async () => {
    const vv = videoRef.current;
    const pr = poseRef.current;

    // ì‹¤í–‰/ë§ˆìš´íŠ¸/ë ˆë”” ìƒíƒœ ëª¨ë‘ ì²´í¬
    if (!runningRef.current) return;
    if (!pr || !vv) return;
    if (vv.readyState < 2) return;            // HAVE_CURRENT_DATA ë¯¸ë§Œì´ë©´ íŒ¨ìŠ¤
    if (!vv.videoWidth || !vv.videoHeight) return;

    try {
      await pr.send({ image: vv });
    } catch (e) {
      // í”„ë ˆì„ ìŠ¤í‚µ
      // console.warn("pose.send failed", e);
    }
  },
  width: 1280,
  height: 720,
});

      await cameraRef.current.start();
      setFeedback("ì²´í˜• ë¶„ì„ ì¤‘... ìì„¸ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.");
    }

    init();
    return () => {
      try { cameraRef.current?.stop?.(); } catch {}
      try { poseRef.current?.close?.(); } catch {}
      cameraRef.current = null;
      poseRef.current = null;
    };
  // â¬‡ï¸ mirroredë§Œ ì˜ì¡´í•˜ë„ë¡ ìˆ˜ì • (running ì œê±°)
  }, [mirrored]);

  return (
    <div style={{ position: "relative", width: "100%", height: "100%" }}>
      <video ref={videoRef} style={{ display: "none" }} muted playsInline autoPlay />
      <canvas
        ref={canvasRef}
        style={{ width: "100%", height: "100%", objectFit: "contain", backgroundColor: "#000", borderRadius: 12 }}
      />
      <p
        style={{
          position: "absolute", top: 10, left: 10,
          background: "rgba(0,0,0,0.7)",
          color: running ? "#0f0" : "#FFFF00",
          padding: "10px", borderRadius: 5, fontSize: 18, margin: 0,
        }}
      >
        {feedback}
      </p>
    </div>
  );
};

export default BodyAnalysisCamera;
