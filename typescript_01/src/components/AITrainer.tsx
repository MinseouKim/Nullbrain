import React, { useEffect, useRef, useState } from "react";
import { Landmark } from "../types/Landmark";
import { handleSquat } from "../logic/exercise/SquatLogic";
import { exerciseHandlers } from "../logic/ExerciseHandler";

interface AITrainerProps {
  exercise: keyof typeof exerciseHandlers;
  isWorkoutPaused: boolean;
  targetReps: number;
  onSetComplete: (data: {
    exerciseName: "squat" | "pushup";
    landmarkHistory: Landmark[][];
    repCount: number;
  }) => Promise<void>;
  currentSet: number;
  totalSets: number;
}

const CDN = {
  cam: "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1640029074/camera_utils.js",
  draw: "https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3.1620248257/drawing_utils.js",
  pose: "https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/pose.js",
};

const AITrainer: React.FC<AITrainerProps> = ({
  exercise,
  isWorkoutPaused,
  targetReps,
  onSetComplete,
  currentSet,
  totalSets,
}) => {
  const [repCount, setRepCount] = useState(0);

  // DOM ìš”ì†Œ ë° Mediapipe ì¸ìŠ¤í„´ìŠ¤ Ref
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const cameraRef = useRef<any>(null);
  const poseRef = useRef<any>(null);

  // ìš´ë™ ë¡œì§ ê´€ë ¨ Ref
  const stage = useRef<"up" | "down">("up");
  const landmarkHistory = useRef<Landmark[][]>([]);

  // onResults ì½œë°±ì—ì„œ 'stale closure' ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•¨
  const stateRef = useRef({ isWorkoutPaused, targetReps });
  useEffect(() => {
    stateRef.current = { isWorkoutPaused, targetReps };
  }, [isWorkoutPaused, targetReps]);

  useEffect(() => {
    setRepCount(0);
    stage.current = "up";
    landmarkHistory.current = [];
    // ì„¸íŠ¸ê°€ ë°”ë€” ë•Œ ë…¹í™” ì„¸ì´í”„í‹°: ì§„í–‰ ì¤‘ì´ë©´ ë§ˆë¬´ë¦¬
    stopRecordingSafely();
  }, [exercise, currentSet]);

  const loadScript = (src: string) =>
    new Promise<void>((resolve, reject) => {
      if (document.querySelector(`script[src="${src}"]`)) return resolve();
      const s = document.createElement("script");
      s.src = src;
      s.crossOrigin = "anonymous";
      s.onload = () => resolve();
      s.onerror = () => reject(new Error(`Script load error: ${src}`));
      document.head.appendChild(s);
    });

  // -----------------------------
  // ğŸ¥ [ì¶”ê°€] MediaRecorder ë…¹í™” ë¡œì§
  // -----------------------------
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordingChunksRef = useRef<Blob[]>([]);
  const isRecordingRef = useRef(false);

  // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ì˜ srcObject(ì›¹ìº  ìŠ¤íŠ¸ë¦¼)ì—ì„œ ë ˆì½”ë” ìƒì„±
  const ensureRecorder = () => {
    if (mediaRecorderRef.current) return mediaRecorderRef.current;
    const vd = videoRef.current as HTMLVideoElement | null;
    const ms = (vd?.srcObject || null) as MediaStream | null;
    if (!ms) return null;
    try {
      const rec = new MediaRecorder(ms, { mimeType: "video/webm" });
      rec.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) recordingChunksRef.current.push(e.data);
      };
      rec.onstop = () => {
        // ì„¸íŠ¸ ì™„ë£Œ ì‹œì ì— stopë˜ë©°, í˜„ì¬ëŠ” ì˜ìƒ ì €ì¥/ì „ë‹¬ ì•ˆí•¨(ìš”êµ¬ì‚¬í•­)
        // í•„ìš”í•˜ë©´ ì—¬ê¸°ì„œ Blobì„ ë‹¤ë£¨ë©´ ë¨.
      };
      mediaRecorderRef.current = rec;
      return rec;
    } catch (e) {
      console.warn("[AITrainer] MediaRecorder init failed:", e);
      return null;
    }
  };

  const startRecordingIfNeeded = () => {
    if (isRecordingRef.current) return;
    const rec = ensureRecorder();
    if (!rec) return;
    recordingChunksRef.current = [];
    try {
      rec.start();
      isRecordingRef.current = true;
      // console.log("[AITrainer] recording started");
    } catch (e) {
      console.warn("[AITrainer] recorder.start() failed:", e);
    }
  };

  const stopRecordingSafely = () => {
    const rec = mediaRecorderRef.current;
    if (rec && isRecordingRef.current) {
      try {
        rec.stop();
      } catch (e) {
        // ì´ë¯¸ ì •ì§€ ìƒíƒœì´ë©´ ë¬´ì‹œ
      }
    }
    isRecordingRef.current = false;
  };

  // ë¶€ëª¨ì— ë„˜ê¸°ëŠ” onSetCompleteë¥¼ ë˜í•‘í•´ì„œ,
  // ë¨¼ì € ë…¹í™”ë¥¼ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•œ ë’¤ ì›ë˜ ì½œë°± í˜¸ì¶œ
  const wrappedOnSetComplete = async (data: {
    exerciseName: "squat" | "pushup";
    landmarkHistory: Landmark[][];
    repCount: number;
  }) => {
    stopRecordingSafely();
    await onSetComplete(data);
  };
  // -----------------------------

  // ì´ í›…ì€ exerciseê°€ ë³€ê²½ë  ë•Œë§Œ ë‹¤ì‹œ ì‹¤í–‰ë¨
  useEffect(() => {
    let isActive = true;
    (async () => {
      try {
        await Promise.all([
          loadScript(CDN.cam),
          loadScript(CDN.draw),
          loadScript(CDN.pose),
        ]);
        await new Promise((resolve) => setTimeout(resolve, 100));
      } catch (err) {
        console.error("Mediapipe ë¡œë”© ì‹¤íŒ¨:", err);
        return;
      }

      const Pose = (window as any).Pose;
      const Camera = (window as any).Camera;
      const drawConnectors = (window as any).drawConnectors;
      const drawLandmarks = (window as any).drawLandmarks;
      const POSE_CONNECTIONS = (window as any).POSE_CONNECTIONS;

      if (!Pose || !Camera || !videoRef.current || !canvasRef.current) return;

      const pose = new Pose({
        locateFile: (f: string) =>
          `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5.1675469404/${f}`,
      });

      pose.setOptions({
        modelComplexity: 1,
        smoothLandmarks: true,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5,
      });
      poseRef.current = pose;

      pose.onResults((results: any) => {
        const canvas = canvasRef.current!;
        const ctx = canvas.getContext("2d")!;
        canvas.width = results.image.width;
        canvas.height = results.image.height;

        ctx.save();
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

        if (results.poseLandmarks) {
          drawConnectors(ctx, results.poseLandmarks, POSE_CONNECTIONS, {
            color: "#00FF00",
            lineWidth: 3,
          });
          drawLandmarks(ctx, results.poseLandmarks, {
            color: "#FF0000",
            lineWidth: 2,
          });

          if (!stateRef.current.isWorkoutPaused) {
            // ğŸ”´ ì¼ì‹œì •ì§€ ìƒíƒœê°€ ì•„ë‹ˆë©´ ì²« í”„ë ˆì„ì—ì„œ ì¦‰ì‹œ ë…¹í™” ì‹œì‘
            startRecordingIfNeeded();

            landmarkHistory.current.push(results.poseLandmarks as Landmark[]);

            const handler = exerciseHandlers[exercise];
            if (handler) {
              // âš ï¸ onSetComplete ëŒ€ì‹  wrappedOnSetComplete ì „ë‹¬ (ë…¹í™” ì¢…ë£Œ í›„ ì› ì½œë°± í˜¸ì¶œ)
              handler(
                results.poseLandmarks,
                stage,
                setRepCount,
                stateRef,
                wrappedOnSetComplete,
                landmarkHistory
              );
            } else {
              console.warn(`[AITrainer] Unknown exercise: ${exercise}`);
            }
          }
        }
        ctx.restore();
      });

      cameraRef.current = new Camera(videoRef.current, {
        onFrame: async () => {
          if (!isActive || !videoRef.current) return;
          try {
            await pose.send({ image: videoRef.current });
          } catch (err) {
            // ê°„í—ì  ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
          }
        },
        width: 1280,
        height: 720,
      });

      await cameraRef.current.start();
      // MediaPipe Cameraê°€ video.srcObjectë¥¼ ì„¸íŒ…í•˜ë¯€ë¡œ, ë ˆì½”ë” ì¤€ë¹„ ì‹œë„
      ensureRecorder();
    })();

    return () => {
      isActive = false;
      stopRecordingSafely();
      try {
        cameraRef.current?.stop?.();
      } catch {}
      try {
        poseRef.current?.close?.();
      } catch {}
      // íŠ¸ë™ ì •ë¦¬
      const vd = videoRef.current;
      const ms = (vd?.srcObject || null) as MediaStream | null;
      ms?.getTracks().forEach((t) => t.stop());
      if (vd) vd.srcObject = null;
    };
  }, [exercise]);

  const setInfo = `Set ${currentSet} / ${totalSets}`;
  const repInfo = `Reps ${repCount} / ${targetReps}`;

  return (
    <div style={{ position: "relative", width: "100%", height: "100%" }}>
      <video ref={videoRef} style={{ display: "none" }} muted playsInline />
      <canvas
        ref={canvasRef}
        style={{
          width: "100%",
          height: "100%",
          objectFit: "contain",
          backgroundColor: "#000",
        }}
      />
      {/* ìƒíƒœ í‘œì‹œ (ì¼ì‹œì •ì§€/ìš´ë™ ì¤‘) */}
      <p
        style={{
          position: "absolute",
          top: 10,
          left: 10,
          background: "rgba(0,0,0,0.7)",
          color: isWorkoutPaused ? "#FFFF00" : "#0f0",
          padding: "10px",
          borderRadius: 5,
          fontSize: 18,
          margin: 0,
        }}
      ></p>
      {/* ì„¸íŠ¸ì™€ íšŸìˆ˜ í‘œì‹œ */}
      <p
        style={{
          position: "absolute",
          bottom: 10,
          left: 10,
          background: "rgba(0,0,0,0.7)",
          color: "#fff",
          padding: "10px",
          borderRadius: 5,
          fontSize: 22,
          fontWeight: "bold",
          margin: 0,
        }}
      >
        {`${setInfo} | ${repInfo}`}
      </p>
    </div>
  );
};

export default AITrainer;
